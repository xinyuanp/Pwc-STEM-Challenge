{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 编码分类器模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from flair.embeddings import TransformerWordEmbeddings,StackedEmbeddings,WordEmbeddings,BytePairEmbeddings\n",
    "from flair.data import Sentence\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from flair.data import Sentence\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import datetime\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#从文件读入数据\n",
    "data = pd.read_excel('output.xlsx',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['搜索项'].values\n",
    "y = data['税收分类编码'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将编码转换为标签\n",
    "tag_to_ix = {}\n",
    "for tag in y:\n",
    "  if tag not in tag_to_ix:\n",
    "    tag_to_ix[tag] = len(tag_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将数据中的编码转化为对应的标签\n",
    "def to_index(data, to_ix):\n",
    "    input_index_list = []\n",
    "    for sent in data:\n",
    "        input_index_list.append([to_ix[sent]])\n",
    "    return input_index_list\n",
    "y = to_index(y,tag_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将数据分为训练和测试数据集\n",
    "#from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#预处理词嵌入包含Word2vec，BytePair和 BERT 并组合到一起\n",
    "#from flair.embeddings import TransformerWordEmbeddings,StackedEmbeddings,WordEmbeddings,BytePairEmbeddings\n",
    "word_embedding = WordEmbeddings('zh')\n",
    "byte_embedding = BytePairEmbeddings('zh')\n",
    "bert_embedding = TransformerWordEmbeddings('bert-base-chinese')\n",
    "stacked_embeddings = StackedEmbeddings(embeddings=[word_embedding,byte_embedding,bert_embedding])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3128/3128 [05:48<00:00,  8.97it/s]\n"
     ]
    }
   ],
   "source": [
    "#将训练数据的语句转换为对应的词嵌入\n",
    "#from flair.data import Sentence\n",
    "#from tqdm import tqdm\n",
    "#import torch\n",
    "train_embedding_matrix = []\n",
    "for i in tqdm(range(len(X_train))):\n",
    "        embeddings = []\n",
    "        sentence = Sentence(X_train[i])\n",
    "        stacked_embeddings.embed(sentence)\n",
    "        for token in sentence:\n",
    "          embeddings.append(token.embedding)\n",
    "        embeddings = torch.stack(embeddings)\n",
    "        embeddings = embeddings.view(-1,1,3472)\n",
    "        train_embedding_matrix.append(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1541/1541 [02:54<00:00,  8.85it/s]\n"
     ]
    }
   ],
   "source": [
    "#将测试数据的语句转换为对应的词嵌入\n",
    "test_embedding_matrix = []\n",
    "for i in tqdm(range(len(X_test))):\n",
    "        embeddings = []\n",
    "        sentence = Sentence(X_test[i])\n",
    "        stacked_embeddings.embed(sentence)\n",
    "        for token in sentence:\n",
    "          embeddings.append(token.embedding)\n",
    "        embeddings = torch.stack(embeddings)\n",
    "        embeddings = embeddings.view(-1,1,3472)\n",
    "        test_embedding_matrix.append(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bi-LSTM模型做特征提取和分类器\n",
    "#from flair.data import Sentence\n",
    "#import torch\n",
    "#import torch.autograd as autograd\n",
    "#import torch.nn as nn\n",
    "#import torch.optim as optim\n",
    "#import torch.nn.functional as F\n",
    "#torch.manual_seed(1)\n",
    "\n",
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self, tag_to_ix,hidden_dim):\n",
    "        super(BiLSTM, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.lstm = nn.LSTM(3472, hidden_dim // 2,\n",
    "                            num_layers=1, bidirectional=True)\n",
    "        self.hidden2tag = nn.Linear(hidden_dim,len(tag_to_ix))\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return (torch.randn(2, 1, self.hidden_dim // 2).to(device),\n",
    "                torch.randn(2, 1, self.hidden_dim // 2).to(device))\n",
    "\n",
    "    def forward(self, embeddings):\n",
    "        self.hidden = self.init_hidden()\n",
    "        embeds = embeddings.view(embeddings.shape[0], 1, -1)\n",
    "        lstm_out, self.hidden = self.lstm(embeds)\n",
    "        lstm_out = lstm_out[0].view(-1, self.hidden_dim)\n",
    "        lstm_feats = self.hidden2tag(lstm_out)\n",
    "        return lstm_feats\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = BiLSTM(tag_to_ix,400).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3128/3128 [03:04<00:00, 16.92it/s]\n",
      "  0%|          | 2/3128 [00:00<03:27, 15.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9026.201347194612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3128/3128 [03:04<00:00, 16.91it/s]\n",
      "  0%|          | 2/3128 [00:00<03:34, 14.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4433.006144646555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3128/3128 [03:05<00:00, 16.84it/s]\n",
      "  0%|          | 2/3128 [00:00<03:35, 14.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2457.4429139094427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3128/3128 [03:04<00:00, 16.98it/s]\n",
      "  0%|          | 2/3128 [00:00<03:31, 14.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1439.8204600595636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3128/3128 [03:05<00:00, 16.89it/s]\n",
      "  0%|          | 2/3128 [00:00<03:29, 14.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "892.1794277280569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3128/3128 [03:04<00:00, 16.94it/s]\n",
      "  0%|          | 1/3128 [00:00<05:57,  8.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "583.8416432402591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3128/3128 [03:17<00:00, 15.82it/s]\n",
      "  0%|          | 1/3128 [00:00<06:14,  8.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "401.08044403341773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3128/3128 [03:17<00:00, 15.85it/s]\n",
      "  0%|          | 2/3128 [00:00<03:40, 14.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288.2998350953967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3128/3128 [03:15<00:00, 16.00it/s]\n",
      "  0%|          | 2/3128 [00:00<03:33, 14.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224.25874061568175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 346/3128 [00:20<02:34, 18.04it/s]"
     ]
    }
   ],
   "source": [
    "#用训练模型对模型进行训练\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.0001, weight_decay=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "best_model = None\n",
    "best_accuracy = 0\n",
    "for epoch in range(15):  \n",
    "    train_loss = 0\n",
    "    model.train()\n",
    "    for i in tqdm(range(len(X_train))):\n",
    "        embeddings = train_embedding_matrix[i]\n",
    "        tags_index = y_train[i]\n",
    "        model.zero_grad()\n",
    "        outputs = model(embeddings)\n",
    "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
    "        loss = criterion(outputs,targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss+=loss.item()  \n",
    "    print(train_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#在测试数据上进行测试\n",
    "def argmax(vec,k):\n",
    "    prob, idx = torch.torch.topk(vec, k)\n",
    "    return prob.tolist(),idx.tolist()\n",
    "\n",
    "correct = 0\n",
    "for i in range(len(y_test)):\n",
    "  embedding = test_embedding_matrix[i]\n",
    "  model.eval()\n",
    "  result = model(embedding)\n",
    "  prob = F.softmax(result,dim=1)\n",
    "  prob = argmax(prob,5)\n",
    "  output = [item for sublist in prob[1] for item in sublist]\n",
    "  prob = [item for sublist in prob[0] for item in sublist]\n",
    "  # print(X_test[i],y_test[i][0],output,prob) #示例\n",
    "  if y_test[i][0] in output:       \n",
    "        correct+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9318624269954575\n"
     ]
    }
   ],
   "source": [
    "#test data的准确性\n",
    "print(correct/len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type BiLSTM. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "#模型保存\n",
    "torch.save(model,'model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Online Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#online learning 给定新输入的数据进行训练，并保存新模型\n",
    "def online_learning(X_train,y_train,lr=0.0001,epoch=15):\n",
    "    train_embedding_matrix = []\n",
    "    for i in tqdm(range(len(X_train))):\n",
    "        embeddings = []\n",
    "        sentence = Sentence(X_train[i])\n",
    "        stacked_embeddings.embed(sentence)\n",
    "        for token in sentence:\n",
    "          embeddings.append(token.embedding)\n",
    "        embeddings = torch.stack(embeddings)\n",
    "        embeddings = embeddings.view(-1,1,1936)\n",
    "        train_embedding_matrix.append(embeddings)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    for epoch in range(epoch): \n",
    "        train_loss = 0\n",
    "        model.train()\n",
    "        for i in tqdm(range(len(X_train))):\n",
    "            embeddings = train_embedding_matrix[i]\n",
    "            tags_index = y_train[i]\n",
    "            model.zero_grad()\n",
    "            outputs = model(embeddings)\n",
    "            targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
    "            loss = criterion(outputs,targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss+=loss.item()  \n",
    "        print(train_loss)\n",
    "    torch.save(model,'model.pt')"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m46"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
